{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Load the data\n",
    "# Remove the punctuation using a linear replacement and convert the sentences into single lines of\n",
    "# text. Also, convert everything to upper or lower case\n",
    "import os\n",
    "import glob\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def load_folder(folder_path):\n",
    "    files = glob.glob(os.path.join(folder_path, '*.txt'))\n",
    "    file_contents = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, \"r\") as f:\n",
    "            # Remove punctuation, convert to single line, and convert to lowercase\n",
    "            #contents = f.read().translate(str.maketrans('', '', string.punctuation))\n",
    "            #contents = tokenize.sent_tokenize(f.read())\n",
    "            #contents = contents.lower()\n",
    "            #contents = contents.replace('\\n', ' ')\n",
    "            contents = f.read()\n",
    "        \n",
    "            file_contents.append(contents)\n",
    "            \n",
    "    return file_contents, files\n",
    "\n",
    "\n",
    "def load_sentences(file_contents):\n",
    "    sentences = []\n",
    "    \n",
    "    for file in file_contents:\n",
    "        sentences.append(list(sent_tokenize(file)))\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found sentence: i asked  in file ./Lab3.2\\02.txt  at index  195\n",
      "Found sentence: i asked  in file ./Lab3.2\\03.txt  at index  5\n",
      "Found sentence: i asked  in file ./Lab3.2\\03.txt  at index  5\n",
      "Found sentence: i asked  in file ./Lab3.2\\03.txt  at index  5\n",
      "Found sentence: i asked  in file ./Lab3.2\\03.txt  at index  5\n",
      "Found sentence: tompkins  in file ./Lab3.2\\03.txt  at index  192\n",
      "Found sentence: 1 wall street  in file ./Lab3.2\\04.txt  at index  1\n",
      "Found sentence: tompkins  in file ./Lab3.2\\04.txt  at index  25\n",
      "Found sentence: i asked  in file ./Lab3.2\\04.txt  at index  70\n",
      "Found sentence: i said  in file ./Lab3.2\\04.txt  at index  159\n",
      "Found sentence: tompkins  in file ./Lab3.2\\05.txt  at index  88\n",
      "Found sentence: i asked  in file ./Lab3.2\\05.txt  at index  131\n",
      "Found sentence: why  in file ./Lab3.2\\05.txt  at index  214\n",
      "Found sentence: i asked  in file ./Lab3.2\\07.txt  at index  18\n",
      "Found sentence: i asked  in file ./Lab3.2\\07.txt  at index  18\n",
      "Found sentence: tompkins  in file ./Lab3.2\\08.txt  at index  117\n",
      "Found sentence: i said  in file ./Lab3.2\\08.txt  at index  146\n",
      "Found sentence: tompkins  in file ./Lab3.2\\08.txt  at index  117\n",
      "Found sentence: i asked  in file ./Lab3.2\\08.txt  at index  160\n",
      "Found sentence: i asked  in file ./Lab3.2\\08.txt  at index  160\n",
      "Found sentence: tompkins  in file ./Lab3.2\\09.txt  at index  136\n",
      "Found sentence: tompkins  in file ./Lab3.2\\09.txt  at index  136\n",
      "Found sentence: i asked  in file ./Lab3.2\\10.txt  at index  18\n",
      "Found sentence: tompkins  in file ./Lab3.2\\10.txt  at index  78\n",
      "Found sentence: i asked  in file ./Lab3.2\\10.txt  at index  18\n",
      "Found sentence: tompkins  in file ./Lab3.2\\10.txt  at index  78\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_contents, files  = load_folder('./Lab3.2/')\n",
    "sentences = load_sentences(file_contents)\n",
    "\n",
    "# Transform the sentences to remove punctuation and convert to lowercase\n",
    "# O(n^2)\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences[i])):\n",
    "        sentences[i][j] = sentences[i][j].translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "        sentences[i][j] = sentences[i][j].replace('\\n', ' ')\n",
    "\n",
    "# Compare currentFile to all other files. CurrentFile = value between 0 and 9\n",
    "selectedFileIndex = 0\n",
    "currentFile = sentences[selectedFileIndex]\n",
    "\n",
    "filteredSentences = sentences.copy() \n",
    "filteredSentences.pop(selectedFileIndex) \n",
    "filteredFiles = files.copy()\n",
    "filteredFiles.pop(selectedFileIndex)\n",
    "\n",
    "# O(n * n * n)\n",
    "for k in range(len(filteredSentences)): # O(n)\n",
    "    for sent in filteredSentences[k]: # O(n)\n",
    "        if sent in currentFile: \n",
    "            print(\"Found sentence:\", sent , \" in file\" , filteredFiles[k], \" at index \", filteredSentences[k].index(sent)) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
