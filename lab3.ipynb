{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Load the data\n",
    "# Remove the punctuation using a linear replacement and convert the sentences into single lines of\n",
    "# text. Also, convert everything to upper or lower case\n",
    "import os\n",
    "import glob\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def load_folder(folder_path):\n",
    "    files = glob.glob(os.path.join(folder_path, '*.txt'))\n",
    "    file_contents = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, \"r\") as f:\n",
    "            # Remove punctuation, convert to single line, and convert to lowercase\n",
    "            #contents = f.read().translate(str.maketrans('', '', string.punctuation))\n",
    "            #contents = tokenize.sent_tokenize(f.read())\n",
    "            #contents = contents.lower()\n",
    "            #contents = contents.replace('\\n', ' ')\n",
    "            contents = f.read()\n",
    "        \n",
    "            file_contents.append(contents)\n",
    "            \n",
    "    return file_contents\n",
    "\n",
    "\n",
    "def load_sentences(file_contents):\n",
    "    sentences = []\n",
    "    \n",
    "    for file in file_contents:\n",
    "        sentences.append(list(sent_tokenize(file)))\n",
    "\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Create a word list\n",
    "#  Analyse the files to create a word list (a hashed dictionary) replacing the words with numerical\n",
    "# values of the word positions in the list.\n",
    "def create_word_list(files):\n",
    "    words = {}\n",
    "    for content in files:\n",
    "        #Split the content into words\n",
    "        content_words = content.split()\n",
    "        # Add each word to the dictionary if it doesn't already exist\n",
    "        for word in content_words:\n",
    "            word = word.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "            word = word.replace('\\n', ' ')\n",
    "            if word not in words:\n",
    "                words[word] = len(words) + 1\n",
    "    return words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match:  i asked  in file  1\n",
      "Found match:  i asked  in file  2\n",
      "Found match:  i asked  in file  2\n",
      "Found match:  i asked  in file  2\n",
      "Found match:  i asked  in file  2\n",
      "Found match:  nothing at all  in file  2\n",
      "Found match:  winnie  in file  2\n",
      "Found match:  i asked  in file  3\n",
      "Found match:  i sighed  in file  3\n",
      "Found match:  i asked  in file  4\n",
      "Found match:  i tried out the scales and found that my involuntary host weighed over 195 poundsa good deal of it around the middle  in file  5\n",
      "Found match:  i asked  in file  6\n",
      "Found match:  i asked  in file  6\n",
      "Found match:  i suggested  in file  6\n",
      "Found match:  dr rutherford was pacing with surgical precision up and down my den  in file  7\n",
      "Found match:  he looked slightly more selfpossessed than the day before and seemed to be in excellent physical condition  in file  7\n",
      "Found match:  i guessed at the contour beneath my wadded black silk dressing gown and reconsidered my original plan to throw him bodily out of the house for having come without my invitation  in file  7\n",
      "Found match:  i asked  in file  7\n",
      "Found match:  okay  in file  7\n",
      "Found match:  i asked  in file  7\n",
      "Found match:  skip it  in file  8\n",
      "Found match:  i asked  in file  9\n",
      "Found match:  i asked  in file  9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_contents = load_folder('./Lab3.2/')\n",
    "sentences = load_sentences(file_contents)\n",
    "word_list = create_word_list(file_contents)\n",
    "\n",
    "\n",
    "# Transform the sentences to remove punctuation and convert to lowercase\n",
    "# O(n^2)\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences[i])):\n",
    "        sentences[i][j] = sentences[i][j].translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "        sentences[i][j] = sentences[i][j].replace('\\n', ' ')\n",
    "\n",
    "# Compare currentFile to all other files. \n",
    "selectedFileIndex = 1\n",
    "currentFile = sentences[selectedFileIndex]\n",
    "\n",
    "filteredSentences = sentences.copy() # O(n)\n",
    "filteredSentences.pop(selectedFileIndex) # O(n)\n",
    "\n",
    "# O(n * n * n)\n",
    "for k in range(len(filteredSentences)): # O(n)\n",
    "    for sent in filteredSentences[k]: # O(n)\n",
    "        if sent in currentFile: # O(n)\n",
    "            print(\"Found match: \", sent, \" in file \", k+1)        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
