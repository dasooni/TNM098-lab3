{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Load the data\n",
    "# Remove the punctuation using a linear replacement and convert the sentences into single lines of\n",
    "# text. Also, convert everything to upper or lower case\n",
    "import os\n",
    "import glob\n",
    "import string\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def load_folder(folder_path):\n",
    "    files = glob.glob(os.path.join(folder_path, '*.txt'))\n",
    "    file_contents = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, \"r\") as f:\n",
    "            # Remove punctuation, convert to single line, and convert to lowercase\n",
    "            #contents = f.read().translate(str.maketrans('', '', string.punctuation))\n",
    "            #contents = tokenize.sent_tokenize(f.read())\n",
    "            #contents = contents.lower()\n",
    "            #contents = contents.replace('\\n', ' ')\n",
    "            contents = f.read()\n",
    "        \n",
    "            file_contents.append(contents)\n",
    "            \n",
    "    return file_contents, files\n",
    "\n",
    "\n",
    "def load_sentences(file_contents):\n",
    "    sentences = []\n",
    "    \n",
    "    for file in file_contents:\n",
    "        sentences.append(list(sent_tokenize(file)))\n",
    "\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Create a word list\n",
    "#  Analyse the files to create a word list (a hashed dictionary) replacing the words with numerical\n",
    "# values of the word positions in the list.\n",
    "def create_word_list(files):\n",
    "    words = {}\n",
    "    for content in files:\n",
    "        #Split the content into words\n",
    "        content_words = content.split()\n",
    "        # Add each word to the dictionary if it doesn't already exist\n",
    "        for word in content_words:\n",
    "            word = word.translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "            word = word.replace('\\n', ' ')\n",
    "            if word not in words:\n",
    "                words[word] = len(words) + 1\n",
    "    return words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found sentence: i asked  in file ./Lab3.2\\01.txt \n",
      " at index  174\n",
      "Found sentence: i asked  in file ./Lab3.2\\03.txt \n",
      " at index  5\n",
      "Found sentence: i asked  in file ./Lab3.2\\03.txt \n",
      " at index  5\n",
      "Found sentence: i asked  in file ./Lab3.2\\03.txt \n",
      " at index  5\n",
      "Found sentence: i asked  in file ./Lab3.2\\03.txt \n",
      " at index  5\n",
      "Found sentence: nothing at all  in file ./Lab3.2\\03.txt \n",
      " at index  163\n",
      "Found sentence: winnie  in file ./Lab3.2\\03.txt \n",
      " at index  200\n",
      "Found sentence: i asked  in file ./Lab3.2\\04.txt \n",
      " at index  70\n",
      "Found sentence: i sighed  in file ./Lab3.2\\04.txt \n",
      " at index  180\n",
      "Found sentence: i asked  in file ./Lab3.2\\05.txt \n",
      " at index  131\n",
      "Found sentence: i tried out the scales and found that my involuntary host weighed over 195 poundsa good deal of it around the middle  in file ./Lab3.2\\06.txt \n",
      " at index  2\n",
      "Found sentence: i asked  in file ./Lab3.2\\07.txt \n",
      " at index  18\n",
      "Found sentence: i asked  in file ./Lab3.2\\07.txt \n",
      " at index  18\n",
      "Found sentence: i suggested  in file ./Lab3.2\\07.txt \n",
      " at index  82\n",
      "Found sentence: dr rutherford was pacing with surgical precision up and down my den  in file ./Lab3.2\\08.txt \n",
      " at index  18\n",
      "Found sentence: he looked slightly more selfpossessed than the day before and seemed to be in excellent physical condition  in file ./Lab3.2\\08.txt \n",
      " at index  19\n",
      "Found sentence: i guessed at the contour beneath my wadded black silk dressing gown and reconsidered my original plan to throw him bodily out of the house for having come without my invitation  in file ./Lab3.2\\08.txt \n",
      " at index  20\n",
      "Found sentence: i asked  in file ./Lab3.2\\08.txt \n",
      " at index  160\n",
      "Found sentence: okay  in file ./Lab3.2\\08.txt \n",
      " at index  161\n",
      "Found sentence: i asked  in file ./Lab3.2\\08.txt \n",
      " at index  160\n",
      "Found sentence: skip it  in file ./Lab3.2\\09.txt \n",
      " at index  14\n",
      "Found sentence: i asked  in file ./Lab3.2\\10.txt \n",
      " at index  18\n",
      "Found sentence: i asked  in file ./Lab3.2\\10.txt \n",
      " at index  18\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_contents, files  = load_folder('./Lab3.2/')\n",
    "sentences = load_sentences(file_contents)\n",
    "word_list = create_word_list(file_contents)\n",
    "\n",
    "\n",
    "# Transform the sentences to remove punctuation and convert to lowercase\n",
    "# O(n^2)\n",
    "for i in range(len(sentences)):\n",
    "    for j in range(len(sentences[i])):\n",
    "        sentences[i][j] = sentences[i][j].translate(str.maketrans('', '', string.punctuation)).lower()\n",
    "        sentences[i][j] = sentences[i][j].replace('\\n', ' ')\n",
    "\n",
    "# Compare currentFile to all other files. CurrentFile = value between 0 and 9\n",
    "selectedFileIndex = 1\n",
    "currentFile = sentences[selectedFileIndex]\n",
    "\n",
    "filteredSentences = sentences.copy() \n",
    "filteredSentences.pop(selectedFileIndex) \n",
    "filteredFiles = files.copy()\n",
    "filteredFiles.pop(selectedFileIndex)\n",
    "\n",
    "# O(n * n * n)\n",
    "for k in range(len(filteredSentences)): # O(n)\n",
    "    for sent in filteredSentences[k]: # O(n)\n",
    "        if sent in currentFile: \n",
    "            print(\"Found sentence:\", sent , \" in file\" , filteredFiles[k], \" at index \", filteredSentences[k].index(sent)) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
